{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **ГЛАВА 1 – ИНИЦИАЛИЗАЦИЯ ПРОЕКТА**"
      ],
      "metadata": {
        "id": "AzfRGGFFWtsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAE for CLIP – Полный пайплайн проекта\n",
        "\n",
        "Ноутбук выполняет полный цикл работы:\n",
        "\n",
        "1. Подключение дисков  \n",
        "2. Установка зависимостей  \n",
        "3. Проверка данных  \n",
        "4. Загрузка активаций и моделей  \n",
        "5. Оценка качества  \n",
        "6. Интерпретация SAE-фич  \n",
        "7. Формирование отчётов"
      ],
      "metadata": {
        "id": "fYYbXr-rW4G5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1_Импорты"
      ],
      "metadata": {
        "id": "sjiFeEHVLUy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Базовые библиотеки, которые нужны для оркестрации.\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "pX4XsLFsLUT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2_Подключение дисков\n",
        "\n",
        "*   Подключение Google Drive\n",
        "*   Подключение Яндекс.Диска\n",
        "\n"
      ],
      "metadata": {
        "id": "3AHOhdFoLGYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== ПОДКЛЮЧЕНИЕ GOOGLE DRIVE ======\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ====== ПОДКЛЮЧЕНИЕ YANDEX DISK (READ-ONLY) ======\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "YANDEX_MOUNT = \"/content/yadisk\"\n",
        "\n",
        "if not os.path.exists(YANDEX_MOUNT):\n",
        "    os.makedirs(YANDEX_MOUNT)\n",
        "\n",
        "print(\"Подключение Яндекс.Диска через WebDAV...\")\n",
        "\n",
        "!apt-get -y install davfs2\n",
        "\n",
        "webdav_url = \"https://webdav.yandex.ru\"\n",
        "\n",
        "!mount -t davfs https://webdav.yandex.ru /content/yadisk -o ro\n",
        "\n",
        "print(\"\\nДиски успешно подключены:\")\n",
        "print(\"Google Drive: /content/drive/MyDrive\")\n",
        "print(\"Yandex Disk:  /content/yadisk\")\n"
      ],
      "metadata": {
        "id": "Z5BzS7cLTFdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3_Инициализация структуры каталогов"
      ],
      "metadata": {
        "id": "oiLINSdcUOH5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Глобальные пути проекта"
      ],
      "metadata": {
        "id": "_gbcq5EHYJmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "GOOGLE_ROOT = Path(\"/content/drive/MyDrive/SAE_PROJECT\")\n",
        "YANDEX_ROOT = Path(\"/content/yadisk/SAE_PROJECT\")\n",
        "\n",
        "(GOOGLE_ROOT / \"datasets\").mkdir(parents=True, exist_ok=True)\n",
        "(GOOGLE_ROOT / \"activations\").mkdir(parents=True, exist_ok=True)\n",
        "(GOOGLE_ROOT / \"models\").mkdir(parents=True, exist_ok=True)\n",
        "(GOOGLE_ROOT / \"results\").mkdir(parents=True, exist_ok=True)\n",
        "(GOOGLE_ROOT / \"logs\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Структура каталогов создана\")"
      ],
      "metadata": {
        "id": "52D2PsKQUG-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подключение кода проекта"
      ],
      "metadata": {
        "id": "G5ggnRDyUdSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "PROJECT_CODE = \"/content/drive/MyDrive/clip-sae-interpret/clip-sae-interpret_clean\"\n",
        "if PROJECT_CODE not in sys.path:\n",
        "    sys.path.append(PROJECT_CODE)\n",
        "\n",
        "print(\"Код проекта подключен\")"
      ],
      "metadata": {
        "id": "KqhSpruDfaM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ГЛАВА 2 – УСТАНОВКА И ПРОВЕРКА СРЕДЫ"
      ],
      "metadata": {
        "id": "xQlHMrjvYV-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1_Установка зависимостей"
      ],
      "metadata": {
        "id": "LmPJl1b1YbNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Установка зависимостей проекта...\")\n",
        "\n",
        "!pip install -r {PROJECT_CODE}/requirements.txt\n",
        "\n",
        "import torch\n",
        "print(\"\\nПроверка CUDA:\")\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device count:\", torch.cuda.device_count())\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# Базовые библиотеки\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\nЗависимости успешно установлены\")"
      ],
      "metadata": {
        "id": "DQ4qCIyRQfUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2_Установка пакета проекта"
      ],
      "metadata": {
        "id": "w5Vu35b0lkRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Установка пакета проекта в режиме разработки...\")\n",
        "\n",
        "%cd {PROJECT_CODE}\n",
        "!pip install -e .\n",
        "\n",
        "print(\"Пакет проекта установлен\")"
      ],
      "metadata": {
        "id": "7dpcgDUtljAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3_Загрузка конфигурации"
      ],
      "metadata": {
        "id": "5D0fdMcAfjoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "with open(f\"{PROJECT_CODE}/configs/train_config.yaml\") as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "print(\"Конфигурация загружена\")\n"
      ],
      "metadata": {
        "id": "wUY3ZkuLfeKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4_Проверка импортов проекта\n"
      ],
      "metadata": {
        "id": "YLukyoJHlLB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sae_clip.models.clip_wrapper import CLIPWrapper\n",
        "from sae_clip.data.datasets import CIFAR10ZeroShotDataset, Food101ZeroShotDataset\n",
        "\n",
        "print(\"Импорты OK\")"
      ],
      "metadata": {
        "id": "FZzNczxflI_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ГЛАВА 3 – РАБОТЫ С ДАННЫМИ"
      ],
      "metadata": {
        "id": "GTyTM5vaZc5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1_Вспомогательные функции работы с файлам"
      ],
      "metadata": {
        "id": "OpuLGamVfoZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, subprocess\n",
        "\n",
        "def exists_local(path):\n",
        "    return os.path.exists(path)\n",
        "\n",
        "\n",
        "def activations_filename(name):\n",
        "    if name == \"cifar10\":\n",
        "        return \"activations_cifar10_vit_b32.pt\"\n",
        "    if name == \"food101\":\n",
        "        return \"activations_food101_vit_b32.pt\"\n",
        "    return f\"activations_{name}.pt\"\n",
        "\n",
        "\n",
        "def dataset_dirname(name):\n",
        "    if name == \"cifar10\":\n",
        "        return \"cifar-10-batches-py\"\n",
        "    if name == \"food101\":\n",
        "        return \"food-101\"\n",
        "    return name\n",
        "\n",
        "\n",
        "def model_dirname(name):\n",
        "    if name == \"cifar10\":\n",
        "        return \"sae_cifar_512d\"\n",
        "    if name == \"food101\":\n",
        "        return \"sae_food101_512d\"\n",
        "    return f\"sae_{name}_512d\"\n",
        "\n",
        "\n",
        "def ensure_dataset(name):\n",
        "    dname = dataset_dirname(name)\n",
        "\n",
        "    local = GOOGLE_ROOT / \"datasets\" / dname\n",
        "    yandex = YANDEX_ROOT / \"datasets\" / dname\n",
        "\n",
        "    print(f\"\\nПроверка датасета: {name}\")\n",
        "\n",
        "    if exists_local(local):\n",
        "        print(f\"Датасет найден в Google Drive: {local}\")\n",
        "        return local\n",
        "\n",
        "    if exists_local(yandex):\n",
        "        print(f\"Датасет найден на Яндекс.Диске: {yandex}\")\n",
        "        print(\"Использование датасета напрямую с Яндекс.Диска\")\n",
        "        return yandex\n",
        "\n",
        "    print(\"Датасет не обнаружен\")\n",
        "    print(\"Начинается скачивание датасета...\")\n",
        "\n",
        "    subprocess.run([\n",
        "        \"python\",\n",
        "        f\"{PROJECT_CODE}/scripts/download_dataset.py\",\n",
        "        name,\n",
        "        str(local)\n",
        "    ])\n",
        "\n",
        "    print(f\"Датасет загружен: {local}\")\n",
        "    return local\n",
        "\n",
        "\n",
        "def ensure_activations(name):\n",
        "    fname = activations_filename(name)\n",
        "\n",
        "    local = GOOGLE_ROOT / \"activations\" / fname\n",
        "    yandex = YANDEX_ROOT / \"activations\" / fname\n",
        "\n",
        "    print(f\"\\nПроверка CLIP-активаций: {name}\")\n",
        "\n",
        "    if exists_local(local):\n",
        "        print(f\"Активации найдены в Google Drive: {local}\")\n",
        "        return local\n",
        "\n",
        "    print(\"Активации не найдены в Google Drive\")\n",
        "\n",
        "    if exists_local(yandex):\n",
        "        print(f\"Активации найдены на Яндекс.Диске: {yandex}\")\n",
        "        print(\"Копирование активаций в Google Drive...\")\n",
        "\n",
        "        local.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copy(yandex, local)\n",
        "\n",
        "        print(f\"Активации скопированы: {local}\")\n",
        "        return local\n",
        "\n",
        "    print(\"Активации не обнаружены\")\n",
        "    print(\"Начинается извлечение активаций...\")\n",
        "\n",
        "    if name == \"food101\":\n",
        "        subprocess.run([\"python\", f\"{PROJECT_CODE}/scripts/extract_clip_activations_food101.py\"])\n",
        "    else:\n",
        "        subprocess.run([\"python\", f\"{PROJECT_CODE}/scripts/extract_clip_activations_cifar10.py\"])\n",
        "\n",
        "    print(f\"Активации созданы: {local}\")\n",
        "    return local\n",
        "\n",
        "\n",
        "def ensure_model(name):\n",
        "    dname = model_dirname(name)\n",
        "\n",
        "    local = GOOGLE_ROOT / \"models\" / dname\n",
        "    yandex = YANDEX_ROOT / \"models\" / dname\n",
        "\n",
        "    print(f\"\\nПроверка модели SAE: {name}\")\n",
        "\n",
        "    if exists_local(local):\n",
        "        print(f\"Модель найдена в Google Drive: {local}\")\n",
        "        return local\n",
        "\n",
        "    print(\"Модель не найдена в Google Drive\")\n",
        "\n",
        "    if exists_local(yandex):\n",
        "        print(f\"Модель найдена на Яндекс.Диске: {yandex}\")\n",
        "        print(\"Копирование модели в Google Drive...\")\n",
        "\n",
        "        shutil.copytree(yandex, local, dirs_exist_ok=True)\n",
        "\n",
        "        print(f\"Модель скопирована: {local}\")\n",
        "        return local\n",
        "\n",
        "    print(\"Модель не обнаружена\")\n",
        "    print(\"Начинается обучение модели SAE...\")\n",
        "\n",
        "    subprocess.run([\"python\", f\"{PROJECT_CODE}/scripts/train_sae.py\", name])\n",
        "\n",
        "    print(f\"Модель обучена: {local}\")\n",
        "    return local\n"
      ],
      "metadata": {
        "id": "Dn4lR-WwfeHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ГЛАВА 4 – ЗАГРУЗКА ДАТАСЕТОВ И АКТИВАЦИЙ"
      ],
      "metadata": {
        "id": "DFMtwuzmaInP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1_Загрузка датасетов"
      ],
      "metadata": {
        "id": "dEnffK-FoGPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "GOOGLE_ROOT = Path(\"/content/drive/MyDrive/SAE_PROJECT\")\n",
        "YANDEX_ROOT = Path(\"/content/yadisk/SAE_PROJECT\")\n",
        "PROJECT_CODE = Path(\"/content/drive/MyDrive/clip-sae-interpret/clip-sae-interpret_clean\")\n",
        "\n",
        "DATASETS = [\"cifar10\", \"food101\"]"
      ],
      "metadata": {
        "id": "mlOdJcMzChLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sae_clip.data.datasets import CIFAR10ZeroShotDataset, Food101ZeroShotDataset\n",
        "\n",
        "print(\"Загрузка датасетов...\")\n",
        "\n",
        "datasets = {}\n",
        "\n",
        "for name in DATASETS:\n",
        "    path = ensure_dataset(name)\n",
        "\n",
        "    print(f\"\\nИнициализация датасета {name} из: {path}\")\n",
        "\n",
        "    if name == \"cifar10\":\n",
        "        datasets[name] = CIFAR10ZeroShotDataset(root=str(path))\n",
        "\n",
        "    elif name == \"food101\":\n",
        "        # для torchvision Food101 root должен быть каталог, содержащий папку food-101\n",
        "        parent_root = str(path.parent)\n",
        "\n",
        "        print(\"Используем root для Food101:\", parent_root)\n",
        "\n",
        "        datasets[name] = Food101ZeroShotDataset(root=parent_root)\n",
        "\n",
        "    print(f\"Датасет {name} успешно загружен\")\n",
        "\n",
        "print(\"\\nВсе датасеты готовы\")\n"
      ],
      "metadata": {
        "id": "SC875wPmoCVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2_Загрузка CLIP-активаций"
      ],
      "metadata": {
        "id": "OHHlIV9fnpeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cоздание активаций для CIFAR-10\n",
        "- делал его на Kaggle и загрузи его на яндекс диск"
      ],
      "metadata": {
        "id": "-pkJ1vZTdwuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Извлечь активации 512D\n",
        "'''\n",
        "!python scripts/extract_clip_activations_cifar10.py \\\n",
        "  --data_root /content/yadisk/SAE_PROJECT/datasets \\\n",
        "  --output_path /content/drive/MyDrive/SAE_PROJECT/activations/activations_cifar10_vit_b32.pt \\\n",
        "  --train_split\n",
        "'''"
      ],
      "metadata": {
        "id": "o3IYCUd0duUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cоздание активаций для food-101\n",
        "- делал его на Kaggle и загрузи его на яндекс диск"
      ],
      "metadata": {
        "id": "GuSzWKoAdbBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Извлечь активации 512D\n",
        "'''\n",
        "!python scripts/extract_clip_activations_food101_fixed.py \\\n",
        "  --images_dir datasets/food-101/images \\\n",
        "  --output_path /content/drive/MyDrive/SAE_PROJECT/activations/activations_food101_vit_b32.pt \\\n",
        "  --max_images 101000\n",
        "'''"
      ],
      "metadata": {
        "id": "RHTU147bdbgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"Загрузка CLIP-активаций...\")\n",
        "\n",
        "activations = {}\n",
        "\n",
        "for name in DATASETS:\n",
        "    path = ensure_activations(name)\n",
        "\n",
        "    print(f\"Загрузка активаций из файла: {path}\")\n",
        "    data = torch.load(path)\n",
        "\n",
        "    activations[name] = data\n",
        "    print(f\"Активации {name} успешно загружены, shape: {data.shape}\")\n",
        "\n",
        "print(\"Все активации готовы\")\n"
      ],
      "metadata": {
        "id": "KUgMp-u3npNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3_Загрузка моделей SAE"
      ],
      "metadata": {
        "id": "FudM3cljt9Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение cifar-10 (можно сделать на kaggle) - запускается если нет на дисках\n",
        "!python scripts/train_sae_google_only.py \\\n",
        "  --dataset cifar10 \\\n",
        "  --epochs 50 \\\n",
        "  --batch_size 256 \\\n",
        "  --lr 0.0005 \\\n",
        "  --l1_coef 0.001 \\\n",
        "  --latent_dim 4096"
      ],
      "metadata": {
        "id": "NdwoXTO4gKrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение food-101 (можно сделать на kaggle) - запускается если нет на дисках\n",
        "!python scripts/train_sae_google_only.py \\\n",
        "  --dataset food101 \\\n",
        "  --epochs 50 \\\n",
        "  --batch_size 256 \\\n",
        "  --lr 0.0005 \\\n",
        "  --l1_coef 0.001 \\\n",
        "  --latent_dim 4096"
      ],
      "metadata": {
        "id": "F-Vbv3qDgMf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sae_clip.models.sae import SparseAutoencoder\n",
        "import re\n",
        "\n",
        "print(\"Загрузка моделей SAE...\")\n",
        "\n",
        "models = {}\n",
        "\n",
        "for name in DATASETS:\n",
        "    path = ensure_model(name)\n",
        "\n",
        "    print(f\"\\nЗагрузка модели из каталога: {path}\")\n",
        "\n",
        "    # поиск всех файлов вида sae_epoch_XX.pt\n",
        "    pt_files = [f for f in os.listdir(path) if f.endswith(\".pt\")]\n",
        "\n",
        "    if not pt_files:\n",
        "        raise FileNotFoundError(f\"Не найден ни один файл .pt в каталоге: {path}\")\n",
        "\n",
        "    # извлечение номера эпохи и сортировка\n",
        "    def get_epoch(fname):\n",
        "        m = re.search(r\"epoch_(\\d+)\", fname)\n",
        "        return int(m.group(1)) if m else -1\n",
        "\n",
        "    pt_files = sorted(pt_files, key=get_epoch)\n",
        "\n",
        "    # выбор последнего (максимальная эпоха)\n",
        "    weight_file = os.path.join(path, pt_files[-1])\n",
        "\n",
        "    print(f\"Найдено файлов: {pt_files}\")\n",
        "    print(f\"Выбран последний чекпоинт: {weight_file}\")\n",
        "\n",
        "    model = SparseAutoencoder(input_dim=512, latent_dim=4096)\n",
        "\n",
        "    state = torch.load(weight_file, map_location=\"cpu\")\n",
        "    model.load_state_dict(state)\n",
        "\n",
        "    models[name] = model\n",
        "\n",
        "    print(f\"Модель {name} успешно загружена из {pt_files[-1]}\")\n",
        "\n",
        "print(\"\\nВсе модели готовы\")\n"
      ],
      "metadata": {
        "id": "8sTobbosxoWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4_Проверка работы моделей"
      ],
      "metadata": {
        "id": "QV8MHeDkzfUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Проверка работы моделей...\")\n",
        "\n",
        "for name in DATASETS:\n",
        "    x = activations[name][:10]\n",
        "\n",
        "    # корректное приведение типов\n",
        "    x = x.detach().clone().float()\n",
        "\n",
        "    x_hat, z = models[name](x)\n",
        "\n",
        "    print(f\"{name}: вход {x.shape} → выход {x_hat.shape}\")\n",
        "\n",
        "print(\"Тестовый инференс выполнен успешно\")\n"
      ],
      "metadata": {
        "id": "CkXAtDIRxrer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5_Тестовый инференс моделей"
      ],
      "metadata": {
        "id": "ahWXGO_z0SjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Тестовый инференс моделей...\")\n",
        "\n",
        "for name in DATASETS:\n",
        "    x = activations[name][:10]\n",
        "\n",
        "    # корректное приведение типов\n",
        "    x = x.detach().clone().float()\n",
        "\n",
        "    x_hat, z = models[name](x)\n",
        "\n",
        "    print(f\"{name}: вход {x.shape} → выход {x_hat.shape}\")\n",
        "\n",
        "print(\"Тестовый инференс выполнен успешно\")\n"
      ],
      "metadata": {
        "id": "RtA_UpDF0A1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6_Расчёт метрик SAE"
      ],
      "metadata": {
        "id": "EB_Y8rJVzTL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sae_clip.models.sae import SparseAutoencoder\n",
        "\n",
        "print(\"Расчёт метрик моделей...\\n\")\n",
        "\n",
        "metrics = {}\n",
        "\n",
        "for name in DATASETS:\n",
        "    print(f\"Оценка для датасета: {name}\")\n",
        "\n",
        "    x = activations[name].detach().clone().float()\n",
        "\n",
        "    model = models[name]\n",
        "    x_hat, z = model(x)\n",
        "\n",
        "    mse = SparseAutoencoder.reconstruction_loss(x, x_hat).item()\n",
        "    l1 = SparseAutoencoder.l1_sparsity(z).item()\n",
        "    l0 = SparseAutoencoder.l0_sparsity(z).item()\n",
        "\n",
        "    metrics[name] = {\n",
        "        \"mse\": mse,\n",
        "        \"l1_sparsity\": l1,\n",
        "        \"l0_sparsity\": l0\n",
        "    }\n",
        "\n",
        "    print(f\"MSE: {mse:.6f}\")\n",
        "    print(f\"L1 sparsity: {l1:.6f}\")\n",
        "    print(f\"L0 sparsity: {l0:.6f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(\"\\nМетрики рассчитаны\")\n"
      ],
      "metadata": {
        "id": "W66SxuWtxrcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7_Извлечение латентов для каждого датасета"
      ],
      "metadata": {
        "id": "A1_2U_co1SnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Извлечение латентных представлений SAE...\")\n",
        "\n",
        "latents = {}\n",
        "\n",
        "for name in DATASETS:\n",
        "    x = activations[name].detach().clone().float()\n",
        "    _, z = models[name](x)\n",
        "\n",
        "    latents[name] = z\n",
        "\n",
        "    print(f\"{name}: latents shape = {z.shape}\")\n",
        "\n",
        "print(\"\\nЛатентные представления готовы\")\n"
      ],
      "metadata": {
        "id": "P-YS5jIX1Q-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8_Базовая статистика латентов"
      ],
      "metadata": {
        "id": "jbdKh_Ks1h7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Статистика латентных признаков...\\n\")\n",
        "\n",
        "for name in DATASETS:\n",
        "    z = latents[name]\n",
        "\n",
        "    print(f\"Dataset: {name}\")\n",
        "    print(\"Min:\", z.min().item())\n",
        "    print(\"Max:\", z.max().item())\n",
        "    print(\"Mean:\", z.mean().item())\n",
        "    print(\"Non-zero ratio:\", (z > 0).float().mean().item())\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "nGCzVbro1Qxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9_Самые активные латенты"
      ],
      "metadata": {
        "id": "znz9hOwA2kMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Поиск наиболее активных SAE-фич...\\n\")\n",
        "\n",
        "top_features = {}\n",
        "\n",
        "for name in DATASETS:\n",
        "    z = latents[name]\n",
        "\n",
        "    mean_activation = z.mean(dim=0)\n",
        "    topk = torch.topk(mean_activation, k=20)\n",
        "\n",
        "    top_features[name] = topk.indices\n",
        "\n",
        "    print(f\"{name}: топ-20 наиболее активных фич:\")\n",
        "    print(topk.indices.tolist())\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "vzxaSTwJxrZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10_Наименее активные признаки"
      ],
      "metadata": {
        "id": "WjYt6A4W2r8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Поиск наименее активных SAE-фич...\\n\")\n",
        "\n",
        "rare_features = {}\n",
        "\n",
        "for name in DATASETS:\n",
        "    z = latents[name]\n",
        "\n",
        "    mean_activation = z.mean(dim=0)\n",
        "    bottomk = torch.topk(mean_activation, k=20, largest=False)\n",
        "\n",
        "    rare_features[name] = bottomk.indices\n",
        "\n",
        "    print(f\"{name}: топ-20 наименее активных фич:\")\n",
        "    print(bottomk.indices.tolist())\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "xOxmcHUqxrXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11_Дополнитеьлные функции"
      ],
      "metadata": {
        "id": "jppfuhpl20gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Примеры для выбранной фичи\n",
        "def show_top_examples(name, feature_index, k=10):\n",
        "    print(f\"\\nТоп-{k} примеров для фичи {feature_index} в датасете {name}\")\n",
        "\n",
        "    z = latents[name]\n",
        "    values = z[:, feature_index]\n",
        "\n",
        "    topk = torch.topk(values, k=k)\n",
        "\n",
        "    print(\"Значения активации:\", topk.values.tolist())\n",
        "    print(\"Индексы примеров:\", topk.indices.tolist())\n"
      ],
      "metadata": {
        "id": "1zO6M8dPxrUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12_Демонстрация"
      ],
      "metadata": {
        "id": "RKOnw-qZbngc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Демонстрация\n",
        "for name in DATASETS:\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"Dataset:\", name)\n",
        "\n",
        "    f = top_features[name][0].item()\n",
        "    show_top_examples(name, f)"
      ],
      "metadata": {
        "id": "sMkiMb0nnpIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13_Сохранение анализа"
      ],
      "metadata": {
        "id": "Vl83KdZD3Evw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "analysis = {\n",
        "    name: {\n",
        "        \"top_features\": top_features[name].tolist(),\n",
        "        \"rare_features\": rare_features[name].tolist()\n",
        "    }\n",
        "    for name in DATASETS\n",
        "}\n",
        "\n",
        "out = GOOGLE_ROOT / \"results\" / \"sae_feature_analysis.json\"\n",
        "\n",
        "with open(out, \"w\") as f:\n",
        "    json.dump(analysis, f, indent=4)\n",
        "\n",
        "print(\"Анализ SAE-фич сохранён в:\", out)\n"
      ],
      "metadata": {
        "id": "11Lh2r-rnpFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14_Подготовка CLIP-обёртки"
      ],
      "metadata": {
        "id": "Zk16b0Ee3lGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sae_clip.models.clip_wrapper import CLIPWrapper\n",
        "\n",
        "print(\"Загрузка CLIP-модели...\")\n",
        "\n",
        "clip = CLIPWrapper()\n",
        "\n",
        "print(\"CLIP готов\")\n"
      ],
      "metadata": {
        "id": "mTbGXg8_3igG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ГЛАВА 5 – БАЗОВАЯ ОЦЕНКА"
      ],
      "metadata": {
        "id": "R1t7UY46cNic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1_Получение текстовых эмбеддингов классов"
      ],
      "metadata": {
        "id": "xjf7xKb_3ve-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Генерация текстовых эмбеддингов...\")\n",
        "\n",
        "text_embeddings = {}\n",
        "\n",
        "for name in DATASETS:\n",
        "    dataset = datasets[name]\n",
        "\n",
        "    class_names = list(dataset.classes)\n",
        "\n",
        "    print(f\"\\nДатасет: {name}\")\n",
        "    print(f\"Количество классов: {len(class_names)}\")\n",
        "\n",
        "    emb = clip.encode_text(class_names)\n",
        "    emb = emb.detach().clone().float()\n",
        "\n",
        "    text_embeddings[name] = emb\n",
        "\n",
        "    print(f\"{name}: получено {emb.shape[0]} текстовых эмбеддингов, размерность {emb.shape[1]}\")\n"
      ],
      "metadata": {
        "id": "m55SLF4x3iYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2_Zero-shot baseline CLIP"
      ],
      "metadata": {
        "id": "op0cirSh6mUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(dataset):\n",
        "    # для CIFAR10ZeroShotDataset\n",
        "    if hasattr(dataset, \"labels\"):\n",
        "        return dataset.labels\n",
        "\n",
        "    # для Food101ZeroShotDataset (обёртка над torchvision)\n",
        "    if hasattr(dataset, \"ds\"):\n",
        "        if hasattr(dataset.ds, \"targets\"):\n",
        "            return dataset.ds.targets\n",
        "        if hasattr(dataset.ds, \"_labels\"):\n",
        "            return dataset.ds._labels\n",
        "\n",
        "    raise ValueError(\"Не удалось определить метки датасета\")\n"
      ],
      "metadata": {
        "id": "cEF5raMi7O2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3_Zero-shot оценка на исходных CLIP-активациях"
      ],
      "metadata": {
        "id": "pwkmVoYicaz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(\"Zero-shot оценка на исходных CLIP-активациях...\\n\")\n",
        "\n",
        "baseline_results = {}\n",
        "\n",
        "device = torch.device(\"cpu\")   # работаем в одном устройстве\n",
        "\n",
        "for name in DATASETS:\n",
        "    print(f\"Оценка для датасета: {name}\")\n",
        "\n",
        "    labels = torch.tensor(get_labels(datasets[name]), dtype=torch.long, device=device)\n",
        "\n",
        "    x = activations[name][:len(labels)].detach().clone().float().to(device)\n",
        "    t = text_embeddings[name].detach().clone().float().to(device)\n",
        "\n",
        "    logits = x @ t.T\n",
        "    preds = logits.argmax(dim=1)\n",
        "\n",
        "    acc = (preds == labels).float().mean().item()\n",
        "\n",
        "    baseline_results[name] = acc\n",
        "\n",
        "    print(f\"{name}: baseline accuracy = {acc:.4f}\")\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "nUgc8WqF3iVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4_Zero-shot оценка с использованием SAE"
      ],
      "metadata": {
        "id": "Cf9HepMlcf_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Zero-shot оценка с использованием SAE...\\n\")\n",
        "\n",
        "sae_results = {}\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "for name in DATASETS:\n",
        "    print(f\"Оценка для датасета: {name}\")\n",
        "\n",
        "    labels = torch.tensor(get_labels(datasets[name]), dtype=torch.long, device=device)\n",
        "\n",
        "    x = activations[name][:len(labels)].detach().clone().float().to(device)\n",
        "\n",
        "    model = models[name].to(device)\n",
        "    x_hat, _ = model(x)\n",
        "\n",
        "    t = text_embeddings[name].detach().clone().float().to(device)\n",
        "\n",
        "    logits = x_hat @ t.T\n",
        "    preds = logits.argmax(dim=1)\n",
        "\n",
        "    acc = (preds == labels).float().mean().item()\n",
        "\n",
        "    sae_results[name] = acc\n",
        "\n",
        "    print(f\"{name}: SAE accuracy = {acc:.4f}\")\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "id": "-bLdcemr3iTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5_Сравнение результатов"
      ],
      "metadata": {
        "id": "hNBzQvFocm3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nСравнение результатов:\\n\")\n",
        "\n",
        "for name in DATASETS:\n",
        "    print(name)\n",
        "    print(f\"Baseline CLIP: {baseline_results[name]:.4f}\")\n",
        "    print(f\"SAE-based:     {sae_results[name]:.4f}\")\n",
        "    print(\"=\" * 40)"
      ],
      "metadata": {
        "id": "lUcMBM8f3iQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6_Запуск официальной оценки"
      ],
      "metadata": {
        "id": "W0Z5AzzedEKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/evaluate_sae_full.py \\\n",
        "  --data_root /content/yadisk/SAE_PROJECT/datasets \\\n",
        "  --food_samples 10000 \\\n",
        "  --batch_size 128 \\\n",
        "  --results_dir /content/drive/MyDrive/SAE_PROJECT/results_full"
      ],
      "metadata": {
        "id": "96zCbG7pdC9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я делелал на kaggle отчет ниже."
      ],
      "metadata": {
        "id": "dwFTdrDhg6IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n=== ЗАГРУЗКА ИТОГОВЫХ РЕЗУЛЬТАТОВ ===\")\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/SAE_PROJECT/results\")\n",
        "\n",
        "csv_path = BASE / \"results.csv\"\n",
        "json_path = BASE / \"results.json\"\n",
        "\n",
        "# Чтение данных\n",
        "if csv_path.exists():\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(\"Результаты загружены из CSV:\", csv_path)\n",
        "elif json_path.exists():\n",
        "    df = pd.read_json(json_path)\n",
        "    print(\"Результаты загружены из JSON:\", json_path)\n",
        "else:\n",
        "    raise FileNotFoundError(\"Не найден results.csv или results.json\")\n",
        "\n",
        "print(\"\\nИсходные данные:\")\n",
        "display(df)\n",
        "\n",
        "# Приведение к формату таблицы SUMMARY\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Печать в текстовом формате\n",
        "for _, row in df.iterrows():\n",
        "    dataset = row.get(\"dataset\", row.get(\"Dataset\", \"unknown\"))\n",
        "    method  = row.get(\"method\", row.get(\"Method\", \"unknown\"))\n",
        "    acc     = row.get(\"accuracy\", row.get(\"Accuracy\", 0))\n",
        "    note    = row.get(\"note\", row.get(\"Note\", \"\"))\n",
        "\n",
        "    print(f\"{dataset:<20} | {method:<12} | {acc:.4f} | {note}\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "# Дополнительно: формируем таблицу для отображения\n",
        "pretty = df.copy()\n",
        "\n",
        "# Переименование колонок\n",
        "rename_map = {}\n",
        "for c in pretty.columns:\n",
        "    rename_map[c] = c.capitalize()\n",
        "\n",
        "pretty = pretty.rename(columns=rename_map)\n",
        "\n",
        "print(\"Таблица результатов:\")\n",
        "display(pretty)\n"
      ],
      "metadata": {
        "id": "Wa-0GEHFiD8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ГЛАВА 6 – АНАЛИЗ SAE-ФИЧ"
      ],
      "metadata": {
        "id": "znt4YtFfRadW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1_Извлечение топ-активаций"
      ],
      "metadata": {
        "id": "skrRiQUxjxXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Анализ SAE-фич для CIFAR-10 ===\")\n",
        "\n",
        "!python scripts/analyze_sae_features.py \\\n",
        "  --activations_path /content/drive/MyDrive/SAE_PROJECT/activations/activations_cifar10_vit_b32.pt \\\n",
        "  --sae_path /content/drive/MyDrive/SAE_PROJECT/models/sae_cifar_512d/sae_epoch_50.pt \\\n",
        "  --top_k 20 \\\n",
        "  --save_dir /content/drive/MyDrive/SAE_PROJECT/results/cifar10/sae_features\n"
      ],
      "metadata": {
        "id": "4vSghRuxRilr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Анализ SAE-фич для FOOD-101 ===\")\n",
        "\n",
        "!python scripts/analyze_sae_features.py \\\n",
        "  --activations_path /content/drive/MyDrive/SAE_PROJECT/activations/activations_food101_vit_b32.pt \\\n",
        "  --sae_path /content/drive/MyDrive/SAE_PROJECT/models/sae_food101_512d/sae_epoch_50.pt \\\n",
        "  --top_k 20 \\\n",
        "  --save_dir /content/drive/MyDrive/SAE_PROJECT/results/food101/sae_features\n",
        "\n"
      ],
      "metadata": {
        "id": "ujf5YsMjRjg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Интрепритация\n",
        "INTERPRET_DATASETS = [\"cifar10\", \"food101\"]"
      ],
      "metadata": {
        "id": "SN1H4YgvnpCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2_Генерация коллажей (по каждому датасету)"
      ],
      "metadata": {
        "id": "nJcKDPHjP8ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n=== ПРОВЕРКА НАЛИЧИЯ КОЛЛАЖЕЙ ДЛЯ CIFAR И FOOD ===\")\n",
        "\n",
        "BASE_ROOT = \"/content/drive/MyDrive/SAE_PROJECT/results\"\n",
        "EXPECTED = 300\n",
        "\n",
        "\n",
        "def check_dataset(ds):\n",
        "    viz_dir = Path(f\"{BASE_ROOT}/{ds}/feature_viz\")\n",
        "    print(f\"\\nПроверка датасета: {ds}\")\n",
        "    print(\"Папка:\", viz_dir)\n",
        "\n",
        "    if not viz_dir.exists():\n",
        "        print(\"✘ Папка отсутствует\")\n",
        "        return False\n",
        "\n",
        "    pngs = list(viz_dir.glob(\"feature_*.png\"))\n",
        "    print(f\"Найдено коллажей: {len(pngs)} из ожидаемых {EXPECTED}\")\n",
        "\n",
        "    if len(pngs) >= EXPECTED:\n",
        "        print(\"✔ Коллажи готовы\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"✘ Недостаточно коллажей\")\n",
        "        return False\n",
        "\n",
        "\n",
        "ready_cifar = check_dataset(\"cifar10\")\n",
        "ready_food  = check_dataset(\"food101\")\n",
        "\n",
        "print(\"\\nИТОГ ПРОВЕРКИ:\")\n",
        "print(\"CIFAR10 готов:\", ready_cifar)\n",
        "print(\"FOOD101 готов:\", ready_food)\n",
        "\n",
        "\n",
        "def generate_for(ds):\n",
        "    print(f\"\\n=== ГЕНЕРАЦИЯ КОЛЛАЖЕЙ ДЛЯ {ds.upper()} ===\")\n",
        "\n",
        "    BASE = f\"{BASE_ROOT}/{ds}\"\n",
        "    viz_dir = Path(f\"{BASE}/feature_viz\")\n",
        "\n",
        "    if ds == \"food101\":\n",
        "        script = \"visualize_sae_features_food101.py\"\n",
        "        dataset_root = \"/content/yadisk/SAE_PROJECT/datasets/food-101/images\"\n",
        "    else:\n",
        "        script = \"visualize_sae_features.py\"\n",
        "        dataset_root = \"/content/yadisk/SAE_PROJECT/datasets\"\n",
        "\n",
        "    csv_path = f\"{BASE}/sae_features/sae_topk_activations.csv\"\n",
        "\n",
        "    print(\"Скрипт:\", script)\n",
        "    print(\"CSV:\", csv_path)\n",
        "    print(\"Dataset root:\", dataset_root)\n",
        "\n",
        "    !python scripts/{script} \\\n",
        "      --csv_path {csv_path} \\\n",
        "      --dataset_root {dataset_root} \\\n",
        "      --features 300 \\\n",
        "      --grid 3 \\\n",
        "      --save_dir {viz_dir}\n",
        "\n",
        "    print(f\"\\nГенерация завершена для: {ds}\")\n",
        "\n",
        "\n",
        "# --- ГЛАВНАЯ ЛОГИКА ---\n",
        "\n",
        "if ready_cifar and ready_food:\n",
        "    print(\"\\n Коллажи готовы и для CIFAR, и для FOOD.\")\n",
        "    print(\"Генерация полностью пропускается.\")\n",
        "\n",
        "elif not ready_cifar and not ready_food:\n",
        "    print(\"\\n Коллажи отсутствуют для обоих датасетов.\")\n",
        "    print(\"Будет выполнена генерация для CIFAR и FOOD.\")\n",
        "    generate_for(\"cifar10\")\n",
        "    generate_for(\"food101\")\n",
        "\n",
        "elif not ready_cifar:\n",
        "    print(\"\\n Коллажи отсутствуют только для CIFAR10.\")\n",
        "    print(\"Будет выполнена генерация только для CIFAR10.\")\n",
        "    generate_for(\"cifar10\")\n",
        "\n",
        "elif not ready_food:\n",
        "    print(\"\\n Коллажи отсутствуют только для FOOD101.\")\n",
        "    print(\"Будет выполнена генерация только для FOOD101.\")\n",
        "    generate_for(\"food101\")\n"
      ],
      "metadata": {
        "id": "UlbGEtddKGlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ГЛАВА 7 – АВТОИНТЕРПРЕТАЦИЯ"
      ],
      "metadata": {
        "id": "4sc37hfKbSzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# запускаем автоматическую интерпретацию фич SAE с помощью визуальных промптов и\n",
        "# VLM (OpenRouter / BLIP‑2) по коллажам картинок для каждой фичи\n",
        "# на этапе 1 интерпретация фич SAE идёт через внешнюю сильную VLM (через OpenRouter, хорошо понимающую русский/английский и сложные инструкции);\n",
        "# когда лимит/токены кончились, скрипт автоматически переключается в режим локальной BLIP‑2 (модель для image→text, без интернета), но ей лучше давать промпты на английском;\n",
        "# итог — для каждой фичи SAE получается автоматически сгенерированное человеческое текстовое описание визуального паттерна, который эта фича ловит\n",
        "# sae_auto_interpretations.csv - дописываемая!!!!\n",
        "# т.к. я потратил уже весь лимит на экспериментах, за денги решил через OpenRouter\n",
        "# (model openai/gpt-4o-mini) выполнить автоматическую интерпретаци только 200 вместо 300 (50 русских + 50 ангискийх )\n",
        "\n",
        "#     рекомендованный промт\n",
        "#   промт для CIFAR10\n",
        "#\"Опишите в одном кратком предложении на русском языке, какая визуальная концепция является общей для всех изображений в этом коллаже. Избегайте слов \"коллаж\", \"изображения\", \"разнообразие\", \"разнообразный\".\"\n",
        "#\"Describe in one concise English sentence what visual concept is common across all images in this collage. Avoid the words collage, images, variety, various.\"\n",
        "#   промт для FOOD-101\n",
        "# \"Identify ONE shared food-related concept. Answer in a short English phrase (4–8 words). Avoid the words collage, images, variety, various. Focus on a concrete dish, ingredient, cooking method, or texture.\"\n",
        "# \"Определите ОДНО общее понятие, связанное с едой. Ответьте короткой фразой на русском языке (4-8 слов). Избегайте слов \"коллаж\", \"изображения\", \"разнообразие\", \"разнообразный\". Сосредоточьтесь на конкретном блюде, ингредиенте, способе приготовления или текстуре."
      ],
      "metadata": {
        "id": "fHQ5dsLzwcYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1_Выбор датасета и языка анализа"
      ],
      "metadata": {
        "id": "yFGOPbx2wu9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Выбор датасета и языка анализа\n",
        "def choose_option(title, options):\n",
        "    print(title)\n",
        "    for k, v in options.items():\n",
        "        print(f\"{k} - {v}\")\n",
        "    choice = input(\"Введите номер: \").strip()\n",
        "    if choice not in options:\n",
        "        raise ValueError(\"Неверный выбор\")\n",
        "    return options[choice]\n",
        "\n",
        "DATASET = choose_option(\n",
        "    \"Выберите датасет:\",\n",
        "    {\"1\": \"cifar10\", \"2\": \"food101\"}\n",
        ")\n",
        "\n",
        "LANG = choose_option(\n",
        "    \"Выберите язык анализа:\",\n",
        "    {\"1\": \"en\", \"2\": \"ru\"}\n",
        ")\n",
        "\n",
        "print(\"\\nИтог:\")\n",
        "print(\"DATASET =\", DATASET)\n",
        "print(\"LANG =\", LANG)\n"
      ],
      "metadata": {
        "id": "b5YjupdWwf2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2_Ввод промпта"
      ],
      "metadata": {
        "id": "GxvNnZBKkf2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== ВВОД ПРОМПТОВ ДЛЯ ДВУЯЗЫЧНОЙ ИНТЕРПРЕТАЦИИ ===\")\n",
        "\n",
        "print(\"\\nТекущий датасет:\", DATASET)\n",
        "\n",
        "# ---- Промпт по умолчанию (EN) ----\n",
        "default_en = (\n",
        "\"Describe in one concise English sentence what visual concept is common \"\n",
        "\"across all images in this collage.\"\n",
        ")\n",
        "\n",
        "print(\"\\nПромпт по умолчанию (EN):\")\n",
        "print(default_en)\n",
        "print(\"\\nВведите свой английский промпт или нажмите Enter для использования стандартного.\")\n",
        "\n",
        "user_en = input(\"PROMPT EN: \").strip()\n",
        "\n",
        "if user_en == \"\":\n",
        "    PROMPT_EN = default_en\n",
        "else:\n",
        "    PROMPT_EN = user_en\n",
        "\n",
        "\n",
        "# ---- Промпт по умолчанию (RU) ----\n",
        "default_ru = (\n",
        "\"Опишите в одном кратком предложении на русском языке, какая визуальная \"\n",
        "\"концепция является общей для всех изображений в этом коллаже.\"\n",
        ")\n",
        "\n",
        "print(\"\\nПромпт по умолчанию (RU):\")\n",
        "print(default_ru)\n",
        "print(\"\\nВведите свой русский промпт или нажмите Enter для использования стандартного.\")\n",
        "\n",
        "user_ru = input(\"PROMPT RU: \").strip()\n",
        "\n",
        "if user_ru == \"\":\n",
        "    PROMPT_RU = default_ru\n",
        "else:\n",
        "    PROMPT_RU = user_ru\n",
        "\n",
        "\n",
        "print(\"\\n=== ИСПОЛЬЗУЕМЫЕ ПРОМПТЫ ===\")\n",
        "print(\"\\n[EN]:\", PROMPT_EN)\n",
        "print(\"\\n[RU]:\", PROMPT_RU)\n"
      ],
      "metadata": {
        "id": "jm0A0CMM2f6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3_Генерация английских описаний"
      ],
      "metadata": {
        "id": "VsrNiFPSkt8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация английских описаний (Автоинтерпретация на английском языке)\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "print(\"\\n=== АВТОИНТЕРПРЕТАЦИЯ (ENGLISH) ===\")\n",
        "\n",
        "key = getpass(\"Введите OPENROUTER_API_KEY (EN): \")\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = key\n",
        "\n",
        "try:\n",
        "    !python scripts/auto_interpret_sae_universal.py \\\n",
        "      --images_dir /content/drive/MyDrive/SAE_PROJECT/results/{DATASET}/feature_viz \\\n",
        "      --num_features 50 \\\n",
        "      --save_csv /content/drive/MyDrive/SAE_PROJECT/results/{DATASET}/interpretations_en.csv \\\n",
        "      --model openai/gpt-4o-mini \\\n",
        "      --prompt \"{PROMPT_EN}\"\n",
        "finally:\n",
        "    del os.environ[\"OPENROUTER_API_KEY\"]\n",
        "    del key\n"
      ],
      "metadata": {
        "id": "1vE93blRw8M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4_Генерация русских описаний"
      ],
      "metadata": {
        "id": "5iDCou-zky6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация русских описаний (Автоинтерпретация на русском языке)\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "print(\"\\n=== АВТОИНТЕРПРЕТАЦИЯ (RUSSIAN) ===\")\n",
        "\n",
        "key = getpass(\"Введите OPENROUTER_API_KEY (RU): \")\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = key\n",
        "\n",
        "try:\n",
        "    !python scripts/auto_interpret_sae_universal.py \\\n",
        "      --images_dir /content/drive/MyDrive/SAE_PROJECT/results/{DATASET}/feature_viz \\\n",
        "      --num_features 50 \\\n",
        "      --save_csv /content/drive/MyDrive/SAE_PROJECT/results/{DATASET}/interpretations_ru.csv \\\n",
        "      --model openai/gpt-4o-mini \\\n",
        "      --prompt \"{PROMPT_RU}\"\n",
        "finally:\n",
        "    del os.environ[\"OPENROUTER_API_KEY\"]\n",
        "    del key\n"
      ],
      "metadata": {
        "id": "84d3q9vqwfzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5_Объединение RU и EN для сравнения"
      ],
      "metadata": {
        "id": "hdGr2EJH4-5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Объединение RU и EN для сравнения\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n=== СОЗДАНИЕ ОБЪЕДИНЁННОГО ФАЙЛА ДЛЯ СРАВНЕНИЯ RU ↔ EN ===\")\n",
        "\n",
        "BASE = f\"/content/drive/MyDrive/SAE_PROJECT/results/{DATASET}\"\n",
        "\n",
        "en_path = f\"{BASE}/interpretations_en.csv\"\n",
        "ru_path = f\"{BASE}/interpretations_ru.csv\"\n",
        "\n",
        "print(\"Файл EN:\", en_path)\n",
        "print(\"Файл RU:\", ru_path)\n",
        "\n",
        "en = pd.read_csv(en_path)\n",
        "ru = pd.read_csv(ru_path)\n",
        "\n",
        "# Объединяем по feature_id\n",
        "bilingual = en.merge(ru, on=\"feature_id\", suffixes=(\"_en\", \"_ru\"))\n",
        "\n",
        "bilingual_path = f\"{BASE}/interpretations_bilingual.csv\"\n",
        "bilingual.to_csv(bilingual_path, index=False)\n",
        "\n",
        "print(\"\\nОбъединённый файл сохранён:\")\n",
        "print(bilingual_path)\n",
        "print(\"Размер таблицы:\", bilingual.shape)\n",
        "\n",
        "print(\"\\nПример строк:\")\n",
        "display(bilingual.head(10))\n"
      ],
      "metadata": {
        "id": "JRyVO03fwfxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ГЛАВА 8 – ОЧИСТКА И АНАЛИЗ"
      ],
      "metadata": {
        "id": "te2kQJ5wk_8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1_Выбор языка для анализа"
      ],
      "metadata": {
        "id": "BLdvNBS6lP3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Выбор языка для анализа\n",
        "print(\"\\n=== НАСТРОЙКА АНАЛИЗА ===\")\n",
        "print(\"Текущий датасет:\", DATASET)\n",
        "print(\"Текущий язык анализа:\", LANG)\n",
        "\n",
        "BASE = f\"/content/drive/MyDrive/SAE_PROJECT/results/{DATASET}\"\n",
        "\n",
        "INPUT = f\"{BASE}/interpretations_{LANG}.csv\"\n",
        "CLEAN = f\"{BASE}/interpretations_clean_{LANG}.csv\"\n",
        "LOG_CLEAN = f\"{BASE}/cleaning_{LANG}.log\"\n",
        "LOG_ANALYZE = f\"{BASE}/analysis_{LANG}.log\"\n",
        "REPORT = f\"{BASE}/final_report_{LANG}.txt\"\n",
        "\n",
        "print(\"\\nФайлы для анализа:\")\n",
        "print(\"Входной файл:\", INPUT)\n",
        "print(\"Очищенный файл:\", CLEAN)\n",
        "print(\"Отчёт:\", REPORT)\n"
      ],
      "metadata": {
        "id": "lcwdznJ7wfuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2_Очистка интерпретаций"
      ],
      "metadata": {
        "id": "rSL7gVKylTxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Очистка интерпретаций\n",
        "print(\"\\n=== ОЧИСТКА ИНТЕРПРЕТАЦИЙ ===\")\n",
        "\n",
        "!python scripts/clean_interpretations.py \\\n",
        "  --input_csv \"{INPUT}\" \\\n",
        "  --output_csv \"{CLEAN}\" \\\n",
        "  --log_file \"{LOG_CLEAN}\"\n"
      ],
      "metadata": {
        "id": "fpVAWzscwfsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3_Анализ выбранного языка"
      ],
      "metadata": {
        "id": "PMXZTRNylZHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Анализ выбранного языка\n",
        "print(\"\\n=== АНАЛИЗ ИНТЕРПРЕТАЦИЙ ===\")\n",
        "\n",
        "!python scripts/analyze_clean_interpretations.py \\\n",
        "  --input_csv \"{CLEAN}\" \\\n",
        "  --log_file \"{LOG_ANALYZE}\"\n"
      ],
      "metadata": {
        "id": "gsTrnlNcwfpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4_Формирование финального отчёта"
      ],
      "metadata": {
        "id": "aIyYxqNJleIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Формирование финального отчёта\n",
        "print(\"\\n=== ФОРМИРОВАНИЕ ОТЧЁТА ===\")\n",
        "\n",
        "!python scripts/report_clean_interpretations.py \\\n",
        "  --input_csv \"{CLEAN}\" \\\n",
        "  --output_report \"{REPORT}\"\n",
        "\n",
        "print(\"\\nОтчёт сохранён:\", REPORT)\n"
      ],
      "metadata": {
        "id": "UL3SjyzOwfnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ГЛАВА 9 – ФИНАЛЬНАЯ ВИЗУАЛИЗАЦИЯ"
      ],
      "metadata": {
        "id": "UkqlsZh4lk8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1_Сравнение RU vs EN с коллажами"
      ],
      "metadata": {
        "id": "HA746X6blp_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Просмотр результатов анализа\n",
        "import pandas as pd\n",
        "\n",
        "print(\"\\n=== ИТОГОВАЯ ТАБЛИЦА (язык анализа:\", LANG, \") ===\")\n",
        "\n",
        "df = pd.read_csv(CLEAN)\n",
        "display(df.head(20))\n"
      ],
      "metadata": {
        "id": "5Ny1YU7ewfkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2_Сравнение RU vs EN с коллажами с визуализацией"
      ],
      "metadata": {
        "id": "j75NXspul3WA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare = bilingual[[\"feature_id\", \"interpretation_en\", \"interpretation_ru\"]]\n"
      ],
      "metadata": {
        "id": "TwhAHLrl8FTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from IPython.display import Image, display, HTML\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n=== ВИЗУАЛЬНАЯ ТАБЛИЦА СРАВНЕНИЯ RU ↔ EN С КОЛЛАЖАМИ ===\")\n",
        "\n",
        "BASE = f\"/content/drive/MyDrive/SAE_PROJECT/results/{DATASET}\"\n",
        "\n",
        "bilingual = pd.read_csv(f\"{BASE}/interpretations_bilingual.csv\")\n",
        "\n",
        "viz_dir = Path(f\"{BASE}/feature_viz\")\n",
        "\n",
        "def find_image(feature_id):\n",
        "    # Формат ваших файлов: feature_0000.png\n",
        "    fname = f\"feature_{int(feature_id):04d}.png\"\n",
        "    path = viz_dir / fname\n",
        "\n",
        "    if path.exists():\n",
        "        return path\n",
        "    return None\n",
        "\n",
        "\n",
        "def show_feature(row):\n",
        "    fid = row[\"feature_id\"]\n",
        "    en = row[\"interpretation_en\"]\n",
        "    ru = row[\"interpretation_ru\"]\n",
        "\n",
        "    html = f\"\"\"\n",
        "    <h3>Feature {fid}</h3>\n",
        "    <b>EN:</b> {en}<br>\n",
        "    <b>RU:</b> {ru}<br><br>\n",
        "    \"\"\"\n",
        "\n",
        "    display(HTML(html))\n",
        "\n",
        "    img = find_image(fid)\n",
        "\n",
        "    if img:\n",
        "        display(Image(filename=str(img), width=300))\n",
        "    else:\n",
        "        print(f\"Коллаж не найден: feature_{int(fid):04d}.png\")\n",
        "\n",
        "\n",
        "N = 20\n",
        "\n",
        "for _, row in bilingual.head(N).iterrows():\n",
        "    show_feature(row)\n"
      ],
      "metadata": {
        "id": "gTB1eJM9wfiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3_Генерация HTML-ОТЧЁТА"
      ],
      "metadata": {
        "id": "Gcgo92A6mHpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"\\n=== ГЕНЕРАЦИЯ ПОЛНОГО HTML-ОТЧЁТА ===\")\n",
        "\n",
        "BASE = f\"/content/drive/MyDrive/SAE_PROJECT/results/{DATASET}\"\n",
        "\n",
        "bilingual_path = f\"{BASE}/interpretations_bilingual.csv\"\n",
        "viz_dir = Path(f\"{BASE}/feature_viz\")\n",
        "\n",
        "df = pd.read_csv(bilingual_path)\n",
        "\n",
        "def image_tag(feature_id):\n",
        "    fname = f\"feature_{int(feature_id):04d}.png\"\n",
        "    path = viz_dir / fname\n",
        "\n",
        "    if path.exists():\n",
        "        return f'<img src=\"feature_viz/{fname}\" width=\"280\">'\n",
        "    else:\n",
        "        return \"<i>image not found</i>\"\n",
        "\n",
        "\n",
        "html_parts = []\n",
        "\n",
        "# ---- Заголовок отчёта ----\n",
        "html_parts.append(f\"\"\"\n",
        "<html>\n",
        "<head>\n",
        "<meta charset=\"utf-8\">\n",
        "<title>SAE Interpretation Report - {DATASET}</title>\n",
        "<style>\n",
        "body {{ font-family: Arial; margin: 30px; }}\n",
        "table {{ border-collapse: collapse; width: 100%; }}\n",
        "th, td {{ border: 1px solid #ccc; padding: 10px; vertical-align: top; }}\n",
        "th {{ background-color: #f0f0f0; }}\n",
        "img {{ border: 1px solid #aaa; }}\n",
        "h1, h2 {{ color: #333; }}\n",
        ".prompt {{ background: #f9f9f9; padding: 10px; border: 1px dashed #aaa; }}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "\"\"\")\n",
        "\n",
        "html_parts.append(f\"<h1>SAE Feature Interpretations Report</h1>\")\n",
        "html_parts.append(f\"<h2>Dataset: {DATASET}</h2>\")\n",
        "\n",
        "# ---- Блок с промптами ----\n",
        "html_parts.append(\"<h2>Used Prompts</h2>\")\n",
        "\n",
        "html_parts.append(\"<h3>English Prompt</h3>\")\n",
        "html_parts.append(f\"<div class='prompt'>{PROMPT_EN}</div>\")\n",
        "\n",
        "html_parts.append(\"<h3>Russian Prompt</h3>\")\n",
        "html_parts.append(f\"<div class='prompt'>{PROMPT_RU}</div>\")\n",
        "\n",
        "html_parts.append(\"<hr>\")\n",
        "\n",
        "# ---- Таблица с результатами ----\n",
        "html_parts.append(\"<h2>Feature Interpretations</h2>\")\n",
        "\n",
        "html_parts.append(\"\"\"\n",
        "<table>\n",
        "<tr>\n",
        "<th>Feature ID</th>\n",
        "<th>Collage</th>\n",
        "<th>English Interpretation</th>\n",
        "<th>Russian Interpretation</th>\n",
        "</tr>\n",
        "\"\"\")\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    fid = row[\"feature_id\"]\n",
        "    en = row[\"interpretation_en\"]\n",
        "    ru = row[\"interpretation_ru\"]\n",
        "\n",
        "    img_html = image_tag(fid)\n",
        "\n",
        "    html_parts.append(f\"\"\"\n",
        "    <tr>\n",
        "        <td><b>{fid}</b></td>\n",
        "        <td>{img_html}</td>\n",
        "        <td>{en}</td>\n",
        "        <td>{ru}</td>\n",
        "    </tr>\n",
        "    \"\"\")\n",
        "\n",
        "html_parts.append(\"</table>\")\n",
        "html_parts.append(\"</body></html>\")\n",
        "\n",
        "report_html = \"\\n\".join(html_parts)\n",
        "\n",
        "report_path = f\"{BASE}/SAE_interpretation_report_{DATASET}.html\"\n",
        "\n",
        "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(report_html)\n",
        "\n",
        "print(\"\\nОтчёт успешно создан:\")\n",
        "print(report_path)\n"
      ],
      "metadata": {
        "id": "m1L7Rf1L7fw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vmh_gGHRiwHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d_3jyXU6iwEZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}