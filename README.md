# SAE for CLIP – Интерпретация эмбеддингов CLIP с помощью Sparse Autoencoder

Данный проект реализует полный исследовательский пайплайн для анализа и интерпретации эмбеддингов модели CLIP с использованием Sparse Autoencoder (SAE).

Проект ориентирован на две популярные визуальные коллекции:

- **CIFAR-10**
- **Food-101**

---

## Цели проекта

Основные задачи, решаемые в рамках работы:

- обучение разреженных автоэнкодеров (SAE) на эмбеддингах CLIP  
- интерпретация скрытых признаков (features), изученных SAE  
- визуализация фич через коллажи изображений  
- автоматическая интерпретация фич с использованием VLM (OpenRouter / GPT-4o-mini)  
- оценка влияния SAE на zero-shot классификацию  
- сравнение результатов до и после применения SAE  

---

## Основные этапы пайплайна

Проект включает следующие шаги:

1. Загрузка и подготовка датасетов  
2. Извлечение CLIP-активаций  
3. Обучение SAE-моделей  
4. Базовая zero-shot оценка CLIP  
5. Оценка качества CLIP + SAE  
6. Анализ активаций SAE  
7. Генерация визуальных коллажей для фич  
8. Автоматическая интерпретация (RU и EN)  
9. Очистка и анализ интерпретаций  
10. Формирование итоговых отчётов  

---

## Структура репозитория
src/ – основной Python-пакет проекта
scripts/ – скрипты для обучения, анализа и визуализации
notebooks/ – рабочие ноутбуки (включая CODE_RUN.ipynb)
requirements.txt – список зависимостей
setup.py – файл установки пакета
.gitignore – исключения для Git
README.md – описание проекта


---

## Установка
Склонируйте репозиторий:
git clone https://github.com/Apelsinhik/sae-clip-project.git
cd sae-clip-project

Установите зависимости:
pip install -r requirements.txt
pip install -e .

## Запуск проекта
Основной сценарий работы реализован в ноутбуке:
notebooks/CODE_RUN.ipynb

Рекомендуемый порядок действий:

1. Открыть ноутбук в Google Colab  
2. Подключить Google Drive  
3. Подключить Яндекс.Диск (read-only)  
4. Ввести OpenRouter API-ключ  
5. Выполнить все ячейки по порядку (Run All)  

Все тяжёлые данные (датасеты, активации, модели, результаты) хранятся на Google Drive и Яндекс.Диске и **не включены в данный репозиторий**.

---

## Результаты экспериментов
Итоговая zero-shot оценка на датасетах:

Таблица результатов:
| № | Датасет  | Метод      | Accuracy ||Notes |
| № |---------|-----------|----------|----------|
| 0	| CIFAR-10	| CLIP	    | 0.889100 |	baseline |
|1	| CIFAR-10	| CLIP+SAE	| 0.857400 |	SAE trained on CIFAR-10 |
|2	| Food-101	| CLIP	    | 0.796000 |	baseline (2000 samples) |
|3	| Food-101	| CLIP+SAE	| 0.789500 |	SAE trained on Food-101 (2000 samples) |
|4	| Food-101	| CLIP	    | 0.801228 |	baseline (25250 samples) |
|5	| Food-101	| CLIP+SAE	| 0.798891 |	SAE trained on Food-101 (25250 samples) |
|6	| Food-101	| CLIP	    | 0.801228 |	baseline (50500 samples) |
|7	|Food-101	| CLIP+SAE	  | 0.798891 |	SAE trained on Food-101 (50500 samples) |


Применение SAE позволяет:
- повысить интерпретируемость эмбеддингов  
- сохранить или немного улучшить точность  
- получить наглядные визуальные признаки  

---

## Особенности реализации
- поддержка двух языков интерпретации (RU и EN)  
- автоматическая очистка и анализ описаний  
- генерация визуальных отчётов  
- воспроизводимый пайплайн в Google Colab  

---

## Ограничения
В репозитории **не хранятся**:
- исходные датасеты  
- извлечённые CLIP-активации  
- обученные модели SAE  
- сгенерированные коллажи и отчёты  

Все эти файлы создаются или загружаются во время выполнения ноутбука.

---


